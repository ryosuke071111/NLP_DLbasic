{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第3回講義　演習　Sequence-to-Sequence（Seq2Seq）モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence-to-Sequence（Seq2Seq）モデルは、系列を入力として系列を出力する機構を持つモデルです。\n",
    "\n",
    "入力系列をRNNでベクトルに変換（=Encoder）し、そのベクトルから別のRNNを用いて系列を生成する（=Decoder）ことから、Encoder-Decoderモデルと呼ばれることもあります。\n",
    "\n",
    "近年の深層学習を用いた自然言語処理ではこの機構を用いた様々なモデルが提案されており、例えば翻訳のタスクにおいては、単純なRNNでは対処が難しかった、言語によって語順や長さが異なる問題に対応することなどが可能になりました。\n",
    "\n",
    "他にも、画像を入力して画像の説明を生成する画像キャプション生成など、数々のタスクへの応用が提案されていますが、今回は翻訳を例として扱います。\n",
    "\n",
    "<img src=\"../images/encoder_decoder.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from nltk import bleu_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "\n",
    "try:\n",
    "    from utils import Vocab\n",
    "except ImportError:  # iLect環境\n",
    "    import os\n",
    "    os.chdir('/root/userspace/chap3/materials')\n",
    "    from utils import Vocab\n",
    "\n",
    "# デバイスの設定\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(1)\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. データセットの準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanaka Corpus ( http://www.edrdg.org/wiki/index.php/Tanaka_Corpus )の一部を抽出した small_parallel_enja: 50k En/Ja Parallel Corpus for Testing SMT Methods ( https://github.com/odashi/small_parallel_enja ) を使います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train.enとtrain.jaの中身は次のようになっています."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i can 't tell who will arrive first .\r\n",
      "many animals have been destroyed by men .\r\n",
      "i 'm in the tennis club .\r\n",
      "emi looks happy .\r\n",
      "please bear this fact in mind .\r\n"
     ]
    }
   ],
   "source": [
    "! head -5 ../data/train.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "誰 が 一番 に 着 く か 私 に は 分か り ま せ ん 。\r\n",
      "多く の 動物 が 人間 に よ っ て 滅ぼ さ れ た 。\r\n",
      "私 は テニス 部員 で す 。\r\n",
      "エミ は 幸せ そう に 見え ま す 。\r\n",
      "この 事実 を 心 に 留め て お い て 下さ い 。\r\n"
     ]
    }
   ],
   "source": [
    "! head -5 ../data/train.ja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 データの読み込みと単語の分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    # テキストファイルからデータを読み込む関数\n",
    "    data = []\n",
    "    for line in open(file_path, encoding='utf-8'):\n",
    "        words = line.strip().split()  # スペースで単語を分割\n",
    "        data.append(words)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = load_data('../data/train.en')\n",
    "train_Y = load_data('../data/train.ja')\n",
    "# 演習用にデータサイズを縮小\n",
    "train_X = train_X[:len(train_X)//2]\n",
    "train_Y = train_Y[:len(train_Y)//2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 訓練データと検証データに分割\n",
    "train_X, valid_X, train_Y, valid_Y = train_test_split(train_X, train_Y, test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'father', 'is', 'very', 'angry', 'with', 'me', '.']\n"
     ]
    }
   ],
   "source": [
    "print(train_X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 単語辞書の作成\n",
    "データセットに登場する各単語にIDを割り振ります。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 特殊なトークンは事前に定義しておく\n",
    "PAD_TOKEN = '<PAD>'  # バッチ処理の際に、短い系列の末尾を埋めるために使う （Padding）\n",
    "BOS_TOKEN = '<S>'  # 系列の始まりを表す （Beggining of sentence）\n",
    "EOS_TOKEN = '</S>'  # 系列の終わりを表す （End of sentence）\n",
    "UNK_TOKEN = '<UNK>'  # 語彙に存在しない単語を表す （Unknown）\n",
    "PAD = 0\n",
    "BOS = 1\n",
    "EOS = 2\n",
    "UNK = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MIN_COUNT = 2  # 語彙に含める単語の最低出現回数\n",
    "\n",
    "# 単語をIDに変換する辞書の初期値を設定\n",
    "word2id = {\n",
    "    PAD_TOKEN: PAD,\n",
    "    BOS_TOKEN: BOS,\n",
    "    EOS_TOKEN: EOS,\n",
    "    UNK_TOKEN: UNK,\n",
    "    }\n",
    "\n",
    "# 単語辞書を作成\n",
    "vocab_X = Vocab(word2id=word2id)\n",
    "vocab_Y = Vocab(word2id=word2id)\n",
    "vocab_X.build_vocab(train_X, min_count=MIN_COUNT)\n",
    "vocab_Y.build_vocab(train_Y, min_count=MIN_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "入力言語の語彙数： 2698\n",
      "出力言語の語彙数： 3051\n"
     ]
    }
   ],
   "source": [
    "vocab_size_X = len(vocab_X.id2word)\n",
    "vocab_size_Y = len(vocab_Y.id2word)\n",
    "print('入力言語の語彙数：', vocab_size_X)\n",
    "print('出力言語の語彙数：', vocab_size_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. テンソルへの変換"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 IDへの変換\n",
    "モデルが文章を認識できるように、Vocabで作成した単語辞書を元に、文章を単語のIDのリストに変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_to_ids(vocab, sentence):\n",
    "    # 単語(str)のリストをID(int)のリストに変換する関数\n",
    "    ids = [vocab.word2id.get(word, UNK) for word in sentence]\n",
    "    ids += [EOS]  # EOSを加える\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = [sentence_to_ids(vocab_X, sentence) for sentence in train_X]\n",
    "train_Y = [sentence_to_ids(vocab_Y, sentence) for sentence in train_Y]\n",
    "valid_X = [sentence_to_ids(vocab_X, sentence) for sentence in valid_X]\n",
    "valid_Y = [sentence_to_ids(vocab_Y, sentence) for sentence in valid_Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 86, 9, 52, 343, 32, 22, 4, 2]\n"
     ]
    }
   ],
   "source": [
    "print(train_X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 DataLoaderの定義\n",
    "データセットからバッチを取得するデータローダを定義します。 \n",
    "- この際、長さの異なる複数の系列をバッチで並列に扱えるように、短い系列の末尾を特定のシンボル（`<PAD>`など）でパディングし、バッチ内の系列の長さを最長のものに合わせます。\n",
    "- (batch_size, max_length)のサイズの行列を得ますが、実際にモデルを学習させるときには、バッチをまたいで各時刻ごとに進めていくので、転置して(max_length, batch_size)の形に変えます。（batch_first=Trueのオプションを使う場合は不要です）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_seq(seq, max_length):\n",
    "    # 系列(seq)が指定の文長(max_length)になるように末尾をパディングする\n",
    "    res = seq + [PAD for i in range(max_length - len(seq))]\n",
    "    return res    \n",
    "\n",
    "\n",
    "class DataLoader(object):\n",
    "\n",
    "    def __init__(self, X, Y, batch_size, shuffle=False):\n",
    "        \"\"\"\n",
    "        :param X: list, 入力言語の文章（単語IDのリスト）のリスト\n",
    "        :param Y: list, 出力言語の文章（単語IDのリスト）のリスト\n",
    "        :param batch_size: int, バッチサイズ\n",
    "        :param shuffle: bool, サンプルの順番をシャッフルするか否か\n",
    "        \"\"\"\n",
    "        self.data = list(zip(X, Y))\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.start_index = 0\n",
    "        \n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        if self.shuffle:  # サンプルの順番をシャッフルする\n",
    "            self.data = shuffle(self.data, random_state=random_state)\n",
    "        self.start_index = 0  # ポインタの位置を初期化する\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        # ポインタが最後まで到達したら初期化する\n",
    "        if self.start_index >= len(self.data):\n",
    "            self.reset()\n",
    "            raise StopIteration()\n",
    "\n",
    "        # バッチを取得\n",
    "        seqs_X, seqs_Y = zip(*self.data[self.start_index:self.start_index+self.batch_size])\n",
    "        # 入力系列seqs_Xの文章の長さ順（降順）に系列ペアをソートする\n",
    "        seq_pairs = sorted(zip(seqs_X, seqs_Y), key=lambda p: len(p[0]), reverse=True)\n",
    "        seqs_X, seqs_Y = zip(*seq_pairs)\n",
    "        # 短い系列の末尾をパディングする\n",
    "        lengths_X = [len(s) for s in seqs_X]  # 後述のEncoderのpack_padded_sequenceでも用いる\n",
    "        lengths_Y = [len(s) for s in seqs_Y]\n",
    "        max_length_X = max(lengths_X)\n",
    "        max_length_Y = max(lengths_Y)\n",
    "        padded_X = [pad_seq(s, max_length_X) for s in seqs_X]\n",
    "        padded_Y = [pad_seq(s, max_length_Y) for s in seqs_Y]\n",
    "        # tensorに変換し、転置する\n",
    "        batch_X = torch.tensor(padded_X, dtype=torch.long, device=device).transpose(0, 1)\n",
    "        batch_Y = torch.tensor(padded_Y, dtype=torch.long, device=device).transpose(0, 1)\n",
    "\n",
    "        # ポインタを更新する\n",
    "        self.start_index += self.batch_size\n",
    "\n",
    "        return batch_X, batch_Y, lengths_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. モデルの構築\n",
    "EncoderとDecoderのRNNを定義します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PackedSequence\n",
    "pytorchのRNNでは、可変長の系列のバッチを効率よく計算できるように系列を表現する`PackedSequence`というクラスを用いることができます。\n",
    "\n",
    "入力のバッチのテンソルをこの`PackedSeauence`のインスタンスに変換してからRNNに入力することで、パディングの部分の計算を省略することができ、効率的な計算が可能になります。\n",
    "(今回は用いませんが、双方向RNNの入力を作成する際も、パディングの方向を考えたりする必要がなくなります。)\n",
    "\n",
    "\n",
    "`PackedSequence`を作成するには、まず、系列長の異なるバッチ(`batch`)に対して、パディングを行います。\n",
    "\n",
    "ここで、パディングを行う前の各サンプルの系列長（`lengths`）を保存しておきます。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "各サンプルの系列長: [4, 3, 2]\n",
      "\n",
      "パディングされたテンソル:\n",
      " tensor([[1, 5, 8],\n",
      "        [2, 6, 9],\n",
      "        [3, 7, 0],\n",
      "        [4, 0, 0]])\n",
      "パディングされたテンソルのサイズ: torch.Size([4, 3])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 系列長がそれぞれ4,3,2の3つのサンプルからなるバッチを作成\n",
    "batch = [[1,2,3,4], [5,6,7], [8,9]]\n",
    "lengths = [len(sample) for sample in batch]\n",
    "print('各サンプルの系列長:', lengths)\n",
    "print()\n",
    "\n",
    "# 最大系列長に合うように各サンプルをパディング\n",
    "_max_length = max(lengths)\n",
    "padded = torch.tensor([pad_seq(sample, _max_length) for sample in batch])\n",
    "padded = padded.transpose(0, 1)  # (max_length, batch_size)に転置\n",
    "print('パディングされたテンソル:\\n', padded)\n",
    "print('パディングされたテンソルのサイズ:', padded.size())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、パディングを行ったテンソル(`padded`)と各サンプルの元々の系列長(`lengths`)を`torch.nn.utils.rnn.pack_padded_sequence`という関数に与えると、\n",
    "`data`と`batch_sizes`という要素を持った`PackedSequence`のインスタンス(`packed`)が作成できます。\n",
    "- `data`: テンソルの`PAD`以外の値のみを保有するベクトル\n",
    "- `batch_sizes`: 各時刻で計算が必要な(=`PAD`に到達していない)バッチの数を表すベクトル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PackedSequenceのインスタンス:\n",
      " PackedSequence(data=tensor([1, 5, 8, 2, 6, 9, 3, 7, 4]), batch_sizes=tensor([3, 3, 2, 1]))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PackedSequenceに変換(テンソルをRNNに入力する前に適用する)\n",
    "packed = pack_padded_sequence(padded, lengths=lengths)  # 各サンプルの系列長も与える\n",
    "print('PackedSequenceのインスタンス:\\n', packed)  # テンソルのPAD以外の値(data)と各時刻で計算が必要な(=PADに到達していない)バッチの数(batch_sizes)を有するインスタンス\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "こうして得られた`PackedSequence`のインスタンスをRNNに入力します。（ここでは省略します）\n",
    "\n",
    "RNNから出力されたテンソルは`PackedSeauence`のインスタンスのままなので、後段の計算につなぐために`torch.nn.utils.rnn.pad_packed_sequence`の関数によって通常のテンソルに戻します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PADを含む元のテンソル:\n",
      " tensor([[1, 5, 8],\n",
      "        [2, 6, 9],\n",
      "        [3, 7, 0],\n",
      "        [4, 0, 0]])\n",
      "各サンプルの系列長: tensor([4, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# PackedSequenceのインスタンスをRNNに入力する（ここでは省略）\n",
    "output = packed\n",
    "\n",
    "# テンソルに戻す(RNNの出力に対して適用する)\n",
    "output, _length = pad_packed_sequence(output)  # PADを含む元のテンソルと各サンプルの系列長を返す\n",
    "print('PADを含む元のテンソル:\\n', output)\n",
    "print('各サンプルの系列長:', _length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回はEncoder側でバッチを処理する際に、`pack_padded_sequence`関数によってtensorを`PackedSequence`に変換し、処理を終えた後に`pad_packed_sequence`関数によってtensorに戻すという処理を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        \"\"\"\n",
    "        :param input_size: int, 入力言語の語彙数\n",
    "        :param hidden_size: int, 隠れ層のユニット数\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size, padding_idx=PAD)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, seqs, input_lengths, hidden=None):\n",
    "        \"\"\"\n",
    "        :param seqs: tensor, 入力のバッチ, size=(max_length, batch_size)\n",
    "        :param input_lengths: 入力のバッチの各サンプルの文長\n",
    "        :param hidden: tensor, 隠れ状態の初期値, Noneの場合は0で初期化される\n",
    "        :return output: tensor, Encoderの出力, size=(max_length, batch_size, hidden_size)\n",
    "        :return hidden: tensor, Encoderの隠れ状態, size=(1, batch_size, hidden_size)\n",
    "        \"\"\"\n",
    "        emb = self.embedding(seqs)\n",
    "        packed = pack_padded_sequence(emb, input_lengths)\n",
    "        output, hidden = self.gru(packed, hidden)\n",
    "        output, _ = pad_packed_sequence(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回はDecoder側ではパディング等を行わないので、通常のtensorのままRNNに入力して問題ありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        \"\"\"\n",
    "        :param hidden_size: int, 隠れ層のユニット数\n",
    "        :param output_size: int, 出力言語の語彙数\n",
    "        :param dropout: float, ドロップアウト率\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size, padding_idx=PAD)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, seqs, hidden):\n",
    "        \"\"\"\n",
    "        :param seqs: tensor, 入力のバッチ, size=(1, batch_size)\n",
    "        :param hidden: tensor, 隠れ状態の初期値, Noneの場合は0で初期化される\n",
    "        :return output: tensor, Decoderの出力, size=(1, batch_size, output_size)\n",
    "        :return hidden: tensor, Decoderの隠れ状態, size=(1, batch_size, hidden_size)\n",
    "        \"\"\"\n",
    "        emb = self.embedding(seqs) # WRITE ME! (Embedding)\n",
    "        output, hidden = self.gru(emb, hidden) # WRITE ME! (RNN)\n",
    "        output = self.out(output) # WRITE ME! (Linear)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EncoderDecoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上で定義したEncoderとDecoderを用いた、一連の処理をまとめるEncoderDecoderのクラスを定義します。\n",
    "\n",
    "ここで、Decoder側の処理で注意する点について説明します。\n",
    "\n",
    "RNNでは、時刻$t$の出力を時刻$t+1$の入力とすることができますが、この方法でDecoderを学習させると連鎖的に誤差が大きくなっていき、学習が不安定になったり収束が遅くなったりする問題が発生します。\n",
    "\n",
    "この問題への対策として**Teacher Forcing**というテクニックがあります。\n",
    "これは、訓練時にはDecoder側の入力に、ターゲット系列（参照訳）をそのまま使うというものです。\n",
    "これにより学習が安定し、収束が早くなるというメリットがありますが、逆に評価時は前の時刻にDecoderが生成したものが使われるため、学習時と分布が異なってしまうというデメリットもあります。\n",
    "\n",
    "Teacher Forcingの拡張として、ターゲット系列を入力とするか生成された結果を入力とするかを確率的にサンプリングする**Scheduled Sampling**という手法があります。\n",
    "\n",
    "ここではScheduled Samplingを採用し、一定の確率に基づいてターゲット系列を入力とするか生成された結果を入力とするかを切り替えられるようにクラスを定義しておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"EncoderとDecoderの処理をまとめる\"\"\"\n",
    "    def __init__(self, input_size, output_size, hidden_size):\n",
    "        \"\"\"\n",
    "        :param input_size: int, 入力言語の語彙数\n",
    "        :param output_size: int, 出力言語の語彙数\n",
    "        :param hidden_size: int, 隠れ層のユニット数\n",
    "        \"\"\"\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = Encoder(input_size, hidden_size)\n",
    "        self.decoder = Decoder(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, batch_X, lengths_X, max_length, batch_Y=None, use_teacher_forcing=False):\n",
    "        \"\"\"\n",
    "        :param batch_X: tensor, 入力系列のバッチ, size=(max_length, batch_size)\n",
    "        :param lengths_X: list, 入力系列のバッチ内の各サンプルの文長\n",
    "        :param max_length: int, Decoderの最大文長\n",
    "        :param batch_Y: tensor, Decoderで用いるターゲット系列\n",
    "        :param use_teacher_forcing: Decoderでターゲット系列を入力とするフラグ\n",
    "        :return decoder_outputs: tensor, Decoderの出力, \n",
    "            size=(max_length, batch_size, self.decoder.output_size)\n",
    "        \"\"\"\n",
    "        # encoderに系列を入力（複数時刻をまとめて処理）\n",
    "        _, encoder_hidden = self.encoder(batch_X, lengths_X)\n",
    "        \n",
    "        _batch_size = batch_X.size(1)\n",
    "\n",
    "        # decoderの入力と隠れ層の初期状態を定義\n",
    "        decoder_input = torch.tensor([BOS] * _batch_size, dtype=torch.long, device=device)\n",
    "        decoder_input = decoder_input.unsqueeze(0)  # (1, batch_size)\n",
    "        decoder_hidden = encoder_hidden  # Encoderの最終隠れ状態を取得\n",
    "\n",
    "        # decoderの出力のホルダーを定義\n",
    "        decoder_outputs = torch.zeros(max_length, _batch_size, self.decoder.output_size, device=device)\n",
    "\n",
    "        # 各時刻ごとに処理\n",
    "        for t in range(max_length):\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "            decoder_outputs[t] = decoder_output\n",
    "            # 次の時刻のdecoderの入力を決定\n",
    "            if use_teacher_forcing and batch_Y is not None:  # ターゲット系列を用いる\n",
    "                decoder_input = batch_Y[t].unsqueeze(0)\n",
    "            else:  # 自身の出力を用いる\n",
    "                decoder_input = decoder_output.max(-1)[1]\n",
    "                \n",
    "        return decoder_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 訓練"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 損失関数の定義\n",
    "基本的には交差エントロピーを損失関数として用いますが、パディングを行うと短い系列の末尾には`<PAD>`トークンが入るため、この部分の損失を計算しないように、マスクをかけます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def masked_cross_entropy(logits, target):\n",
    "    \"\"\"\n",
    "    :param logits: torch.tensor(dtype=torch.float)\n",
    "        Decoderの出力。size=(max_seq_len, batch_size, output_size)\n",
    "    :param target: torch.tensor(dtype=torch.long)\n",
    "        ターゲット系列。 size=(max_seq_len, batch_size)\n",
    "    :return loss: targetのPADの部分を0でマスクされた損失\n",
    "    \"\"\"\n",
    "    logits_flat = logits.view(-1, logits.size(-1))  # (max_seq_len * batch_size, output_size)\n",
    "    log_probs_flat = F.log_softmax(logits_flat, -1)  # (max_seq_len * batch_size, output_size)\n",
    "    target_flat = target.view(-1, 1)  # (max_seq_len * batch_size, 1)\n",
    "    # logitsからtargetのインデックスに該当する要素のみ取得する\n",
    "    losses_flat = -torch.gather(log_probs_flat, dim=1, index=target_flat)  # (max_seq_len * batch_size, 1)\n",
    "    losses = losses_flat.view(*target.size())  # (max_seq_len, batch_size)\n",
    "    # PADが０、それ以外が1のマスクをかけてマスクが1の部分のみ取得\n",
    "    mask = (target != PAD).float()  # (max_seq_len, batch_size)\n",
    "    losses = losses * mask\n",
    "    loss = losses.sum()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.CrossEntropyLoss`を使うと以下のように簡単に書くこともできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mce = nn.CrossEntropyLoss(reduction='sum', ignore_index=PAD)\n",
    "def masked_cross_entropy(logits, target):\n",
    "    return mce(logits.view(-1, logits.size(-1)), target.view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ハイパーパラメータの設定\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "lr = 1e-3  # 学習率\n",
    "teacher_forcing_rate = 0.2  # Teacher Forcingを行う確率\n",
    "ckpt_path = 'model.pth'  # 学習済みのモデルを保存するパス\n",
    "\n",
    "model_args = {\n",
    "    'input_size': vocab_size_X,\n",
    "    'output_size': vocab_size_Y,\n",
    "    'hidden_size': 256,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torch/cuda/__init__.py:117: UserWarning: \n",
      "    Found GPU0 GRID K520 which is of cuda capability 3.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    }
   ],
   "source": [
    "# データローダを定義\n",
    "train_dataloader = DataLoader(train_X, train_Y, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_X, valid_Y, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# モデルとOptimizerを定義\n",
    "model = EncoderDecoder(**model_args).to(device) # iLectで実行する場合warning (GPU is too old) が出ますが, 実行に問題はないので気にせず進めてください.\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際に損失関数を計算する関数を定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_loss(batch_X, batch_Y, lengths_X, model, optimizer=None, is_train=True):\n",
    "    # 損失を計算する関数\n",
    "    model.train(is_train)  # train/evalモードの切替え\n",
    "    \n",
    "    # 一定確率でTeacher Forcingを行う\n",
    "    use_teacher_forcing = is_train and (random.random() < teacher_forcing_rate)\n",
    "    max_length = batch_Y.size(0)\n",
    "    # 推論\n",
    "    pred_Y = model(batch_X, lengths_X, max_length, batch_Y, use_teacher_forcing)\n",
    "    \n",
    "    # 損失関数を計算\n",
    "    loss = masked_cross_entropy(pred_Y.contiguous(), batch_Y.contiguous())\n",
    "    \n",
    "    if is_train:  # 訓練時はパラメータを更新\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    batch_Y = batch_Y.transpose(0, 1).contiguous().data.cpu().tolist()\n",
    "    pred = pred_Y.max(dim=-1)[1].data.cpu().numpy().T.tolist()\n",
    "\n",
    "    return loss.item(), batch_Y, pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで、損失以外に、学習の進捗を確認するためのモデルの性能を評価する指標として、BLEUを計算します。\n",
    "\n",
    "BLEUは機械翻訳の分野において最も一般的な自動評価基準の一つで、予め用意した（複数の）参照訳と、機械翻訳モデルが出力した訳のn-gramのマッチ率に基づく指標です。\n",
    "\n",
    "NLTK（Natural Language Tool Kit）という自然言語処理やテキストマイニングで用いられるライブラリを用いて簡単に計算することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_bleu(refs, hyps):\n",
    "    \"\"\"\n",
    "    BLEUスコアを計算する関数\n",
    "    :param refs: list, 参照訳。単語のリストのリスト (例： [['I', 'have', 'a', 'pen'], ...])\n",
    "    :param hyps: list, モデルの生成した訳。単語のリストのリスト (例： [['I', 'have', 'a', 'pen'], ...])\n",
    "    :return: float, BLEUスコア(0~100)\n",
    "    \"\"\"\n",
    "    refs = [[ref[:ref.index(EOS)]] for ref in refs]\n",
    "    hyps = [hyp[:hyp.index(EOS)] if EOS in hyp else hyp for hyp in hyps]\n",
    "    return 100 * bleu_score.corpus_bleu(refs, hyps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルの訓練を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss: 54.42  train_bleu: 2.25  valid_loss: 51.01  valid_bleu: 3.94\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2: train_loss: 47.20  train_bleu: 5.48  valid_loss: 47.78  valid_bleu: 5.06\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3: train_loss: 43.55  train_bleu: 7.57  valid_loss: 45.62  valid_bleu: 7.71\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4: train_loss: 40.63  train_bleu: 10.29  valid_loss: 44.04  valid_bleu: 8.63\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5: train_loss: 37.88  train_bleu: 12.43  valid_loss: 43.22  valid_bleu: 11.33\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6: train_loss: 35.95  train_bleu: 14.42  valid_loss: 42.57  valid_bleu: 11.40\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7: train_loss: 33.91  train_bleu: 16.55  valid_loss: 42.37  valid_bleu: 12.04\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8: train_loss: 32.58  train_bleu: 17.87  valid_loss: 42.52  valid_bleu: 12.46\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9: train_loss: 30.72  train_bleu: 20.61  valid_loss: 42.53  valid_bleu: 13.57\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10: train_loss: 28.99  train_bleu: 23.19  valid_loss: 42.93  valid_bleu: 14.21\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 訓練\n",
    "best_valid_bleu = 0.\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    train_loss = 0.\n",
    "    train_refs = []\n",
    "    train_hyps = []\n",
    "    valid_loss = 0.\n",
    "    valid_refs = []\n",
    "    valid_hyps = []\n",
    "    # train\n",
    "    for batch in train_dataloader:\n",
    "        batch_X, batch_Y, lengths_X = batch\n",
    "        loss, gold, pred = compute_loss(\n",
    "            batch_X, batch_Y, lengths_X, model, optimizer, \n",
    "            is_train=True\n",
    "            )\n",
    "        train_loss += loss\n",
    "        train_refs += gold\n",
    "        train_hyps += pred\n",
    "    # valid\n",
    "    for batch in valid_dataloader:\n",
    "        batch_X, batch_Y, lengths_X = batch\n",
    "        loss, gold, pred = compute_loss(\n",
    "            batch_X, batch_Y, lengths_X, model, \n",
    "            is_train=False\n",
    "            )\n",
    "        valid_loss += loss\n",
    "        valid_refs += gold\n",
    "        valid_hyps += pred\n",
    "    # 損失をサンプル数で割って正規化\n",
    "    train_loss = np.sum(train_loss) / len(train_dataloader.data)\n",
    "    valid_loss = np.sum(valid_loss) / len(valid_dataloader.data)\n",
    "    # BLEUを計算\n",
    "    train_bleu = calc_bleu(train_refs, train_hyps)\n",
    "    valid_bleu = calc_bleu(valid_refs, valid_hyps)\n",
    "\n",
    "    # validationデータでBLEUが改善した場合にはモデルを保存\n",
    "    if valid_bleu > best_valid_bleu:\n",
    "        ckpt = model.state_dict()\n",
    "        torch.save(ckpt, ckpt_path)\n",
    "        best_valid_bleu = valid_bleu\n",
    "\n",
    "    print('Epoch {}: train_loss: {:5.2f}  train_bleu: {:2.2f}  valid_loss: {:5.2f}  valid_bleu: {:2.2f}'.format(\n",
    "            epoch, train_loss, train_bleu, valid_loss, valid_bleu))\n",
    "        \n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(2698, 256, padding_idx=0)\n",
       "    (gru): GRU(256, 256)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(3051, 256, padding_idx=0)\n",
       "    (gru): GRU(256, 256)\n",
       "    (out): Linear(in_features=256, out_features=3051, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習済みモデルの読み込み\n",
    "ckpt = torch.load(ckpt_path)\n",
    "model.load_state_dict(ckpt)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ids_to_sentence(vocab, ids):\n",
    "    # IDのリストを単語のリストに変換する\n",
    "    return [vocab.id2word[_id] for _id in ids]\n",
    "\n",
    "def trim_eos(ids):\n",
    "    # IDのリストからEOS以降の単語を除外する\n",
    "    if EOS in ids:\n",
    "        return ids[:ids.index(EOS)]\n",
    "    else:\n",
    "        return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# テストデータの読み込み\n",
    "test_X = load_data('../data/dev.en')\n",
    "test_Y = load_data('../data/dev.ja')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X = [sentence_to_ids(vocab_X, sentence) for sentence in test_X]\n",
    "test_Y = [sentence_to_ids(vocab_Y, sentence) for sentence in test_Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_X, test_Y, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src: show your own business .\n",
      "tgt: 自分 の 事 を しろ 。\n",
      "out: 自分 の 仕事 を し 。 。\n"
     ]
    }
   ],
   "source": [
    "# 生成\n",
    "batch_X, batch_Y, lengths_X = next(test_dataloader)\n",
    "sentence_X = ' '.join(ids_to_sentence(vocab_X, batch_X.data.cpu().numpy()[:-1, 0]))\n",
    "sentence_Y = ' '.join(ids_to_sentence(vocab_Y, batch_Y.data.cpu().numpy()[:-1, 0]))\n",
    "print('src: {}'.format(sentence_X))\n",
    "print('tgt: {}'.format(sentence_Y))\n",
    "\n",
    "output = model(batch_X, lengths_X, max_length=20)\n",
    "output = output.max(dim=-1)[1].view(-1).data.cpu().tolist()\n",
    "output_sentence = ' '.join(ids_to_sentence(vocab_Y, trim_eos(output)))\n",
    "print('out: {}'.format(output_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.560598911464778\n"
     ]
    }
   ],
   "source": [
    "# BLEUの計算\n",
    "test_dataloader = DataLoader(test_X, test_Y, batch_size=1, shuffle=False)\n",
    "refs_list = []\n",
    "hyp_list = []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    batch_X, batch_Y, lengths_X = batch\n",
    "    pred_Y = model(batch_X, lengths_X, max_length=20)\n",
    "    pred = pred_Y.max(dim=-1)[1].view(-1).data.cpu().tolist()# WRITE ME! (リストに変換する)\n",
    "    refs = batch_Y.view(-1).data.cpu().tolist()\n",
    "    refs_list.append(refs)\n",
    "    hyp_list.append(pred)\n",
    "bleu = calc_bleu(refs_list, hyp_list)\n",
    "print(bleu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam Search\n",
    "テストデータに対して新たな文を生成する際、これまでは各時刻で最も確率の高い単語を正解として採用し、次のステップでの入力として使っていました。\n",
    "ただ、本当にやりたいのは、文全体の尤度が最も高くなるような文を生成することです。そのため、ただ近視眼的に確率の高い単語を採用していくより、もう少し大局的に評価していく必要があります。\n",
    "\n",
    "Beam Searchでは、各時刻において一定の数$K$のそれまでのスコア(対数尤度など)の高い文を保持しながら選択を行っていきます。  \n",
    "\n",
    "以下の図は、$K=2$とした時の、各ステップにおける出力単語とスコア（簡易的に％で表示しています）を元に、上位2つのパスを保持しながら出力を行う過程を表したものです。\n",
    "\n",
    "各ステップで最もスコアの高い単語（赤色）以外も探索することにより、最終的により累計スコアの高いパス(青色)を得ることができています。\n",
    "\n",
    "<img src=\"../images/BeamSearch.png\" style=\"height: 400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下ではBeam Searchでdecodeを行うクラスの実装例です。\n",
    "\n",
    "※ 実装を簡易にするため、入力は単一のサンプル(batch_size=1)を前提としており、ミニバッチ(batch_size>1)には対応していません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BeamEncoderDecoder(EncoderDecoder):\n",
    "    \"\"\"\n",
    "    Beam Searchでdecodeを行うためのクラス\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, output_size, hidden_size, beam_size=4):\n",
    "        \"\"\"\n",
    "        :param input_size: int, 入力言語の語彙数\n",
    "        :param output_size: int, 出力言語の語彙数\n",
    "        :param hidden_size: int, 隠れ層のユニット数\n",
    "        :param beam_size: int, ビーム数\n",
    "        \"\"\"\n",
    "        super(BeamEncoderDecoder, self).__init__(input_size, output_size, hidden_size)\n",
    "        self.beam_size = beam_size\n",
    "\n",
    "    def forward(self, batch_X, lengths_X, max_length):\n",
    "        \"\"\"\n",
    "        :param batch_X: tensor, 入力系列のバッチ, size=(max_length, batch_size)\n",
    "        :param lengths_X: list, 入力系列のバッチ内の各サンプルの文長\n",
    "        :param max_length: int, Decoderの最大文長\n",
    "        :return decoder_outputs: list, 各ビームのDecoderの出力\n",
    "        :return finished_scores: list of float, 各ビームのスコア\n",
    "        \"\"\"\n",
    "        _, encoder_hidden = self.encoder(batch_X, lengths_X)\n",
    "\n",
    "        # decoderの入力と隠れ層の初期状態を定義\n",
    "        decoder_input = torch.tensor([EOS], dtype=torch.long, device=device) # WRITE ME! (BOSで初期化)\n",
    "        decoder_input = # WRITE ME! (時系列方向の軸(dim=0)を追加する)\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # beam_sizeの数だけrepeatする\n",
    "        decoder_input = decoder_input.expand(1, beam_size)\n",
    "        decoder_hidden = decoder_hidden.expand(1, beam_size, -1).contiguous()\n",
    "\n",
    "        k = beam_size\n",
    "        finished_beams = []\n",
    "        finished_scores = []\n",
    "        prev_probs = torch.zeros(beam_size, 1, dtype=torch.float, device=device)  # 前の時刻の各ビームの対数尤度を保持しておく\n",
    "        output_size = self.decoder.output_size\n",
    "\n",
    "        # 各時刻ごとに処理\n",
    "        for t in range(max_length):\n",
    "            # decoder_input: (1, k)\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input[-1:], decoder_hidden)\n",
    "            # decoder_output: (1, k, output_size)\n",
    "            # decoder_hidden: (1, k, hidden_size)\n",
    "            decoder_output_t = decoder_output[-1]  # (k, output_size)\n",
    "            log_probs = prev_probs + F.log_softmax(decoder_output_t, dim=-1)  # (k, output_size)\n",
    "            scores = log_probs  # 対数尤度をスコアとする\n",
    "\n",
    "            # スコアの高いビームとその単語を取得\n",
    "            flat_scores = scores.view(-1)  # (k*output_size,)\n",
    "            if t == 0:\n",
    "                flat_scores = flat_scores[:output_size]  # t=0のときは後半の同じ値の繰り返しを除外\n",
    "            top_vs, top_is = flat_scores.data.topk(k)\n",
    "            beam_indices = top_is / output_size  # (k,)\n",
    "            word_indices = top_is % output_size  # (k,)\n",
    "            \n",
    "            # ビームを更新する\n",
    "            _next_beam_indices = []\n",
    "            _next_word_indices = []\n",
    "            for b, w in zip(beam_indices, word_indices):\n",
    "                if w.item() == EOS:  # EOSに到達した場合はそのビームは更新して終了\n",
    "                    k -= 1\n",
    "                    beam = torch.cat([decoder_input.t()[b], w.view(1,)])  # (t+2,)\n",
    "                    score = scores[b, w].item()\n",
    "                    finished_beams.append(beam)\n",
    "                    finished_scores.append(score)\n",
    "                else:   # それ以外の場合はビームを更新\n",
    "                    _next_beam_indices.append(b)\n",
    "                    _next_word_indices.append(w)\n",
    "            if k == 0:\n",
    "                break\n",
    "\n",
    "            # tensorｎに変換\n",
    "            next_beam_indices = torch.tensor(_next_beam_indices, device=device)\n",
    "            next_word_indices = torch.tensor(_next_word_indices, device=device)\n",
    "\n",
    "            # 次の時刻のDecoderの入力を更新\n",
    "            decoder_input = torch.index_select(\n",
    "                decoder_input, dim=-1, index=next_beam_indices)\n",
    "            decoder_input = torch.cat(\n",
    "                [decoder_input, next_word_indices.unsqueeze(0)], dim=0)\n",
    "    \n",
    "            # 次の時刻のDecoderの隠れ層を更新\n",
    "            decoder_hidden = torch.index_select(\n",
    "                decoder_hidden, dim=1, index=next_beam_indices)\n",
    "\n",
    "            # 各ビームの対数尤度を更新\n",
    "            flat_probs = log_probs.view(-1)  # (k*output_size,)\n",
    "            next_indices = (next_beam_indices + 1) * next_word_indices\n",
    "            prev_probs = torch.index_select(\n",
    "                flat_probs, dim=0, index=next_indices).unsqueeze(1)  # (k, 1)\n",
    "\n",
    "        # すべてのビームが完了したらデータを整形\n",
    "        decoder_outputs = [[idx.item() for idx in beam[1:-1]] for beam in finished_beams]\n",
    "        \n",
    "        return decoder_outputs, finished_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習済みモデルの読み込み\n",
    "beam_size = 3\n",
    "beam_model = BeamEncoderDecoder(**model_args, beam_size=beam_size).to(device)\n",
    "beam_model.load_state_dict(ckpt)\n",
    "beam_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_X, test_Y, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成\n",
    "batch_X, batch_Y, lengths_X = next(test_dataloader)\n",
    "sentence_X = ' '.join(ids_to_sentence(vocab_X, batch_X.data.cpu().numpy()[:-1, 0]))\n",
    "sentence_Y = ' '.join(ids_to_sentence(vocab_Y, batch_Y.data.cpu().numpy()[:-1, 0]))\n",
    "print('src: {}'.format(sentence_X))\n",
    "print('tgt: {}'.format(sentence_Y))\n",
    "\n",
    "# 普通のdecode\n",
    "output = model(batch_X, lengths_X, max_length=20)\n",
    "output = output.max(dim=-1)[1].view(-1).data.cpu().numpy().tolist()\n",
    "output_sentence = ' '.join(ids_to_sentence(vocab_Y, trim_eos(output)))\n",
    "print('out: {}'.format(output_sentence))\n",
    "\n",
    "# beam decode\n",
    "outputs, scores = beam_model(batch_X, lengths_X, max_length=20)\n",
    "# scoreの良い順にソート\n",
    "outputs, scores = zip(*sorted(zip(outputs, scores), key=lambda x: -x[1]))\n",
    "for o, output in enumerate(outputs):\n",
    "    output_sentence = ' '.join(ids_to_sentence(vocab_Y, output))\n",
    "    print('out{}: {}'.format(o+1, output_sentence))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献\n",
    "- [Practical PyTorch: Translation with a Sequence to Sequence Network and Attention](https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation-batched.ipynb)\n",
    "- [Translation with a Sequence to Sequence Network and Attention](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#sphx-glr-intermediate-seq2seq-translation-tutorial-py)\n",
    "- [Encoder\\-decoderモデルとTeacher Forcing，Scheduled Sampling，Professor Forcing](http://satopirka.com/2018/02/encoder-decoder%E3%83%A2%E3%83%87%E3%83%AB%E3%81%A8teacher-forcingscheduled-samplingprofessor-forcing/)\n",
    "- [Sequence\\-to\\-Sequence Learning as Beam\\-Search Optimization](https://arxiv.org/abs/1606.02960)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
