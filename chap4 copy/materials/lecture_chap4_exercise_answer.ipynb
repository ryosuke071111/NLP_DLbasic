{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第4回 演習（2）Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TransformerはRNNやCNNを使用せず、Attentionのみを用いるSeq2Seqモデルです。\n",
    "\n",
    "並列計算が可能なためRNNに比べて計算が高速な上、Self-Attentionと呼ばれる機構を用いることにより、局所的な位置しか参照できないCNNと異なり、系列内の任意の位置の情報を参照することを可能にしています。\n",
    "\n",
    "その他にもいくつかの工夫が加えられており、翻訳に限らない自然言語処理のあらゆるタスクで圧倒的な性能を示すことが知られています。\n",
    "\n",
    "原論文：[Attention is All You Need](https://arxiv.org/abs/1706.03762)\n",
    "\n",
    "参考実装：https://github.com/jadore801120/attention-is-all-you-need-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from nltk import bleu_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "try:\n",
    "    from utils import Vocab\n",
    "except ImportError:  # iLect環境\n",
    "    import os\n",
    "    os.chdir('/root/userspace/chap4/materials')\n",
    "    from utils import Vocab\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(1)\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "UNK = 1\n",
    "BOS = 2\n",
    "EOS = 3\n",
    "\n",
    "PAD_TOKEN = '<PAD>'\n",
    "UNK_TOKEN = '<UNK>'\n",
    "BOS_TOKEN = '<S>'\n",
    "EOS_TOKEN = '</S>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. データセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    テキストファイルからデータを読み込む\n",
    "    :param file_path: str, テキストファイルのパス\n",
    "    :return data: list, 文章（単語のリスト）のリスト\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for line in open(file_path, encoding='utf-8'):\n",
    "        words = line.strip().split()  # スペースで単語を分割\n",
    "        data.append(words)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/train.en'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-20a5d6c30254>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/train.en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/train.ja'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 演習用にデータサイズを縮小\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-27bcf2587aa7>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \"\"\"\n\u001b[1;32m      7\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# スペースで単語を分割\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/train.en'"
     ]
    }
   ],
   "source": [
    "train_X = load_data('../data/train.en')\n",
    "train_Y = load_data('../data/train.ja')\n",
    "# 演習用にデータサイズを縮小\n",
    "train_X = train_X[:len(train_X)//2]\n",
    "train_Y = train_Y[:len(train_Y)//2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b40d5a0fedee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 訓練データと検証データに分割\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_X' is not defined"
     ]
    }
   ],
   "source": [
    "# 訓練データと検証データに分割\n",
    "train_X, valid_X, train_Y, valid_Y = train_test_split(train_X, train_Y, test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-37c4910a44f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mvocab_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword2id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mvocab_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword2id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mvocab_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMIN_COUNT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mvocab_Y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMIN_COUNT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_X' is not defined"
     ]
    }
   ],
   "source": [
    "MIN_COUNT = 2  # 語彙に含める単語の最低出現回数\n",
    "\n",
    "word2id = {\n",
    "    PAD_TOKEN: PAD,\n",
    "    BOS_TOKEN: BOS,\n",
    "    EOS_TOKEN: EOS,\n",
    "    UNK_TOKEN: UNK,\n",
    "    }\n",
    "\n",
    "vocab_X = Vocab(word2id=word2id)\n",
    "vocab_Y = Vocab(word2id=word2id)\n",
    "vocab_X.build_vocab(train_X, min_count=MIN_COUNT)\n",
    "vocab_Y.build_vocab(train_Y, min_count=MIN_COUNT)\n",
    "\n",
    "vocab_size_X = len(vocab_X.id2word)\n",
    "vocab_size_Y = len(vocab_Y.id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_ids(vocab, sentence):\n",
    "    \"\"\"\n",
    "    単語のリストをインデックスのリストに変換する\n",
    "    :param vocab: Vocabのインスタンス\n",
    "    :param sentence: list of str\n",
    "    :return indices: list of int\n",
    "    \"\"\"\n",
    "    ids = [vocab.word2id.get(word, UNK) for word in sentence]\n",
    "    ids = [BOS] + ids + [EOS]  # </S>トークンを末尾に加える\n",
    "#     ids += [EOS]  # EOSを末尾に加える\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7f03acd941a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msentence_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msentence_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvalid_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msentence_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_X\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvalid_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msentence_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_Y\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_X' is not defined"
     ]
    }
   ],
   "source": [
    "train_X = [sentence_to_ids(vocab_X, sentence) for sentence in train_X]\n",
    "train_Y = [sentence_to_ids(vocab_Y, sentence) for sentence in train_Y]\n",
    "valid_X = [sentence_to_ids(vocab_X, sentence) for sentence in valid_X]\n",
    "valid_Y = [sentence_to_ids(vocab_Y, sentence) for sentence in valid_Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "    def __init__(self, src_insts, tgt_insts, batch_size, shuffle=True):\n",
    "        \"\"\"\n",
    "        :param src_insts: list, 入力言語の文章（単語IDのリスト）のリスト\n",
    "        :param tgt_insts: list, 出力言語の文章（単語IDのリスト）のリスト\n",
    "        :param batch_size: int, バッチサイズ\n",
    "        :param shuffle: bool, サンプルの順番をシャッフルするか否か\n",
    "        \"\"\"\n",
    "        self.data = list(zip(src_insts, tgt_insts))\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.start_index = 0\n",
    "        \n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        if self.shuffle:\n",
    "            self.data = shuffle(self.data, random_state=random_state)\n",
    "        self.start_index = 0\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "\n",
    "        def preprocess_seqs(seqs):\n",
    "            # パディング\n",
    "            max_length = max([len(s) for s in seqs])\n",
    "            data = [s + [PAD] * (max_length - len(s)) for s in seqs]\n",
    "            # 単語の位置を表現するベクトルを作成\n",
    "            positions = [[pos+1 if w != PAD else 0 for pos, w in enumerate(seq)] for seq in data]\n",
    "            # テンソルに変換\n",
    "            data_tensor = torch.tensor(data, dtype=torch.long, device=device)\n",
    "            position_tensor = torch.tensor(positions, dtype=torch.long, device=device)\n",
    "            return data_tensor, position_tensor            \n",
    "\n",
    "        # ポインタが最後まで到達したら初期化する\n",
    "        if self.start_index >= len(self.data):\n",
    "            self.reset()\n",
    "            raise StopIteration()\n",
    "\n",
    "        # バッチを取得して前処理\n",
    "        src_seqs, tgt_seqs = zip(*self.data[self.start_index:self.start_index+self.batch_size])\n",
    "        src_data, src_pos = preprocess_seqs(src_seqs)\n",
    "        tgt_data, tgt_pos = preprocess_seqs(tgt_seqs)\n",
    "\n",
    "        # ポインタを更新する\n",
    "        self.start_index += self.batch_size\n",
    "\n",
    "        return (src_data, src_pos), (tgt_data, tgt_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 各モジュールの定義\n",
    "Transformerのモデルも大きくはEncoder(下図左側）とDecoder（下図右側）からなっており、それぞれ灰色で表されているブロックをN個積み重ねた構造となっています。\n",
    "\n",
    "EncoderとDecoderは\n",
    "- Positional Encoding: 入出力の単語のEmbedding時に単語の位置情報を埋め込む\n",
    "- Scaled Dot-Product Attention: 内積でAttentionを計算し、スケーリングを行う\n",
    "- Multi-head Attention: Scaled Dot-Product Attentionを複数のヘッドで並列化する（下図橙色）\n",
    "- Position-Wise Feed Forward Network: 単語列の位置ごとに独立して処理を行う（下図水色）\n",
    "\n",
    "など、いくつかのモジュールから構成されているため、それぞれのモジュールを定義していきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/Transformer.png\" style=\"height: 600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ① Positional Encoding\n",
    "Transformerは系列の処理にRNNやCNNを使用しないので、そのままでは単語列の語順を考慮することができません。\n",
    "\n",
    "そのため、入力系列の埋込行列に単語の位置情報を埋め込むPositional Encodingを加算します。\n",
    "\n",
    "Positional Encodingの行列${\\bf PE}$の各成分は次式で表されます。\n",
    "\n",
    "$PE_{(pos, 2i)} = \\sin(pos/10000^{2i/d_{model}})$\n",
    "\n",
    "$PE_{(pos, 2i+1)} = \\cos(pos/10000^{2i/d_{model}})$\n",
    "\n",
    "ここで$pos$は単語の位置を、$i$は成分の次元を表しています。\n",
    "\n",
    "Positional Encodingの各次元は、波長が$2\\pi$から$10000*2\\pi$に幾何学的に伸びる正弦波に対応します。\n",
    "\n",
    "未知の系列長にも対応可能であり、また学習は不要です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_encoding_init(n_position, d_pos_vec):\n",
    "    \"\"\"\n",
    "    Positional Encodingのための行列の初期化を行う\n",
    "    :param n_position: int, 系列長\n",
    "    :param d_pos_vec: int, 隠れ層の次元数\n",
    "    :return: torch.tensor, size=(n_position, d_pos_vec)\n",
    "    \"\"\"\n",
    "    # PADがある単語の位置はpos=0にしておき、position_encも0にする\n",
    "    position_enc = np.array([\n",
    "        [pos / np.power(10000, 2 * (j // 2) / d_pos_vec) for j in range(d_pos_vec)]\n",
    "        if pos != 0 else np.zeros(d_pos_vec) for pos in range(n_position)])\n",
    "\n",
    "    position_enc[1:, 0::2] = np.sin(position_enc[1:, 0::2]) # dim 2i\n",
    "    position_enc[1:, 1::2] = np.cos(position_enc[1:, 1::2]) # dim 2i+1\n",
    "    return torch.tensor(position_enc, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positional Encodingを可視化すると以下のようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pe = position_encoding_init(50, 256).numpy()\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.heatmap(pe, cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe[2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "縦軸が単語の位置を、横軸が成分の次元を表しており、濃淡が加算される値です。\n",
    "\n",
    "ここでは最大系列長を50、隠れ層の次元数を256としました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ② Multihead Attention\n",
    "\n",
    "\n",
    "#### Source-Target-AttentionとSelf-Attention\n",
    "\n",
    "Attentionは一般に、queryベクトルとkeyベクトルの類似度を求めて、その正規化した重みをvalueベクトルに適用して値を取り出す処理を行います。\n",
    "\n",
    "一般的な翻訳モデルで用いられるAttentionはSource-Target-Attentionと呼ばれ、この場合queryはDecoderの隠れ状態(Target)、keyはEncoderの隠れ状態（Source）、valueもEncoderの隠れ状態（Source）で表現されるのが一般的です。\n",
    "モデル全体の図では、右側のDecoderのブロックの中央にあるAttentionがこれに該当します。\n",
    "\n",
    "\n",
    "Transformerでは、このSource-Target-Attentionに加えて、query、key、valueを同じ系列内で定義するSelf-Attentionの機構を用います。これにより、ある単語位置の出力を求める際にあらゆる位置を参照できるため、局所的な位置しか参照できない畳み込み層よりも良い性能を発揮できると言われています。\n",
    "モデル全体の図では、左側のEncoderブロックと右側のDecoderのブロックの下部にあるAttentionがこれに該当します。\n",
    "\n",
    "<img src=\"../images/Attention.png\" style=\"width:80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformerでは、Scaled Dot-Product Attentionと呼ばれるAttentionを、複数のヘッドで並列に行うMulti-Head Attentionによって、Source-Target-AttentionとSelf-Attentionを表現します。\n",
    "\n",
    "以下では、Scaled Dot-Product AttentionとMulti-Head Attentionについて順に説明していきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaled Dot-Product Attention\n",
    "Attentionには、注意の重みを隠れ層 1 つのフィードフォワードネットワークで求めるAdditive Attentionと、注意の重みを内積で求めるDot-Product Attentionが存在します。  一般に、Dot-Product Attentionのほうがパラメータが少なく高速であり、Transformerでもこちらを使います。\n",
    "\n",
    "\n",
    "Tranformerではさらなる工夫として、query($Q$)とkey($K$)の内積をスケーリング因子 $\\sqrt{d_k}$ で除算します。\n",
    "\n",
    "$Attention(Q, K, V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V$ \n",
    "\n",
    "\n",
    "これは、$d_k$（keyベクトルの次元数）が大きい場合に内積が大きくなりすぎて逆伝播のsoftmaxの勾配が極端に小さくなることを防ぐ役割を果たします。\n",
    "\n",
    "<img src=\"../images/Multihead.png\" style=\"height: 400px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, d_model, attn_dropout=0.1):\n",
    "        \"\"\"\n",
    "        :param d_model: int, 隠れ層の次元数\n",
    "        :param attn_dropout: float, ドロップアウト率\n",
    "        \"\"\"\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.temper = np.power(d_model, 0.5)  # スケーリング因子\n",
    "        self.dropout = nn.Dropout(attn_dropout)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, q, k, v, attn_mask):\n",
    "        \"\"\"\n",
    "        :param q: torch.tensor, queryベクトル, \n",
    "            size=(n_head*batch_size, len_q, d_k)\n",
    "        :param k: torch.tensor, key, \n",
    "            size=(n_head*batch_size, len_k, d_k)\n",
    "        :param v: torch.tensor, valueベクトル, \n",
    "            size=(n_head*batch_size, len_v, d_v)\n",
    "        :param attn_mask: torch.tensor, Attentionに適用するマスク, \n",
    "            size=(n_head*batch_size, len_q, len_k)\n",
    "        :return output: 出力ベクトル, \n",
    "            size=(n_head*batch_size, len_q, d_v)\n",
    "        :return attn: Attention\n",
    "            size=(n_head*batch_size, len_q, len_k)\n",
    "        \"\"\"\n",
    "        # QとKの内積(上図右側`MatMul`)でAttentionの重みを求め、スケーリングする(上図右側`Scale`)\n",
    "        attn = torch.bmm(q, k.transpose(1, 2)) / self.temper  # (n_head*batch_size, len_q, len_k)\n",
    "        # Attentionをかけたくない部分がある場合は、その部分を負の無限大に飛ばしてSoftmaxの値が0になるようにする(上図右側`Mask(opt.)`)\n",
    "        attn.data.masked_fill_(attn_mask, -float('inf'))\n",
    "        \n",
    "        attn = self.softmax(attn)  # (上図右側`SoftMax`)\n",
    "        attn = self.dropout(attn)\n",
    "        output = torch.bmm(attn, v)  # (上図右側`MatMul`)\n",
    "\n",
    "        return output, attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-Head Attention\n",
    "TransformerではAttentionを複数のヘッドで並列に行うMulti-Head Attentionを採用しています。\n",
    "\n",
    "複数のヘッドでAttentionを行うことにより、各ヘッドが異なる位置の異なる部分空間を処理でき、精度が向上するとされています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_head, d_model, d_k, d_v, dropout=0.1):\n",
    "        \"\"\"\n",
    "        :param n_head: int, ヘッド数\n",
    "        :param d_model: int, 隠れ層の次元数\n",
    "        :param d_k: int, keyベクトルの次元数\n",
    "        :param d_v: int, valueベクトルの次元数\n",
    "        :param dropout: float, ドロップアウト率\n",
    "        \"\"\"\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "\n",
    "        self.n_head = n_head\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "\n",
    "        # 各ヘッドごとに異なる重みで線形変換を行うための重み\n",
    "        # nn.Parameterを使うことで、Moduleのパラメータとして登録できる\n",
    "        self.w_qs = nn.Parameter(torch.empty([n_head, d_model, d_k], dtype=torch.float))\n",
    "        self.w_ks = nn.Parameter(torch.empty([n_head, d_model, d_k], dtype=torch.float))\n",
    "        self.w_vs = nn.Parameter(torch.empty([n_head, d_model, d_v], dtype=torch.float))\n",
    "        # nn.init.xavier_normal_で重みの値を初期化\n",
    "        nn.init.xavier_normal_(self.w_qs)\n",
    "        nn.init.xavier_normal_(self.w_ks)\n",
    "        nn.init.xavier_normal_(self.w_vs)\n",
    "\n",
    "        self.attention = ScaledDotProductAttention(d_model)\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self.proj = nn.Linear(n_head*d_v, d_model)  # 複数ヘッド分のAttentionの結果を元のサイズに写像するための線形層\n",
    "        # nn.init.xavier_normal_で重みの値を初期化\n",
    "        nn.init.xavier_normal_(self.proj.weight)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def forward(self, q, k, v, attn_mask=None):\n",
    "        \"\"\"\n",
    "        :param q: torch.tensor, queryベクトル, \n",
    "            size=(batch_size, len_q, d_model)\n",
    "        :param k: torch.tensor, key, \n",
    "            size=(batch_size, len_k, d_model)\n",
    "        :param v: torch.tensor, valueベクトル, \n",
    "            size=(batch_size, len_v, d_model)\n",
    "        :param attn_mask: torch.tensor, Attentionに適用するマスク, \n",
    "            size=(batch_size, len_q, len_k)\n",
    "        :return outputs: 出力ベクトル, \n",
    "            size=(batch_size, len_q, d_model)\n",
    "        :return attns: Attention\n",
    "            size=(n_head*batch_size, len_q, len_k)\n",
    "            \n",
    "        \"\"\"\n",
    "        d_k, d_v = self.d_k, self.d_v\n",
    "        n_head = self.n_head\n",
    "\n",
    "        # residual connectionのための入力\n",
    "        residual = q\n",
    "\n",
    "        batch_size, len_q, d_model = q.size()\n",
    "        batch_size, len_k, d_model = k.size()\n",
    "        batch_size, len_v, d_model = v.size()\n",
    "\n",
    "        # 複数ヘッド化\n",
    "        # torch.repeat または .repeatで指定したdimに沿って同じテンソルを作成\n",
    "        q_s = q.repeat(n_head, 1, 1) # (n_head*batch_size, len_q, d_model)\n",
    "        k_s = k.repeat(n_head, 1, 1) # (n_head*batch_size, len_k, d_model)\n",
    "        v_s = v.repeat(n_head, 1, 1) # (n_head*batch_size, len_v, d_model)\n",
    "        # ヘッドごとに並列計算させるために、n_headをdim=0に、batch_sizeをdim=1に寄せる\n",
    "        q_s = q_s.view(n_head, -1, d_model) # (n_head, batch_size*len_q, d_model)\n",
    "        k_s = k_s.view(n_head, -1, d_model) # (n_head, batch_size*len_k, d_model)\n",
    "        v_s = v_s.view(n_head, -1, d_model) # (n_head, batch_size*len_v, d_model)\n",
    "\n",
    "        # 各ヘッドで線形変換を並列計算(上図左側`Linear`)\n",
    "        q_s = torch.bmm(q_s, self.w_qs)  # (n_head, batch_size*len_q, d_k)\n",
    "        k_s = torch.bmm(k_s, self.w_ks)  # (n_head, batch_size*len_k, d_k)\n",
    "        v_s = torch.bmm(v_s, self.w_vs)  # (n_head, batch_size*len_v, d_v)\n",
    "        # Attentionは各バッチ各ヘッドごとに計算させるためにbatch_sizeをdim=0に寄せる\n",
    "        q_s = q_s.view(-1, len_q, d_k)   # (n_head*batch_size, len_q, d_k)\n",
    "        k_s = k_s.view(-1, len_k, d_k)   # (n_head*batch_size, len_k, d_k)\n",
    "        v_s = v_s.view(-1, len_v, d_v)   # (n_head*batch_size, len_v, d_v)\n",
    "\n",
    "        # Attentionを計算(上図左側`Scaled Dot-Product Attention * h`)\n",
    "        outputs, attns = self.attention(q_s, k_s, v_s, attn_mask=attn_mask.repeat(n_head, 1, 1))\n",
    "        # outputs: (n_head*batch_size, len_q, d_v)\n",
    "        # attns: (n_head*batch_size, len_q, len_k)\n",
    "        \n",
    "        # 各ヘッドの結果を連結(上図左側`Concat`)\n",
    "        # torch.splitでbatch_sizeごとのn_head個のテンソルに分割\n",
    "        outputs = torch.split(outputs, batch_size, dim=0)  # (batch_size, len_q, d_v) * n_head\n",
    "        # dim=-1で連結\n",
    "        outputs = torch.cat(outputs, dim=-1)  # (batch_size, len_q, n_head*d_v)\n",
    "\n",
    "        # residual connectionのために元の大きさに写像(上図左側`Linear`)\n",
    "        outputs = self.proj(outputs)  # (batch_size, len_q, d_model)\n",
    "        outputs = self.dropout(outputs)\n",
    "        outputs = self.layer_norm(outputs + residual)\n",
    "\n",
    "        return outputs, attns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ③ Position-Wise Feed Forward Network\n",
    "単語列の位置ごとに独立して処理する2層のネットワークであるPosition-Wise Feed Forward Networkを定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"\"\"\n",
    "    :param d_hid: int, 隠れ層1層目の次元数\n",
    "    :param d_inner_hid: int, 隠れ層2層目の次元数\n",
    "    :param dropout: float, ドロップアウト率\n",
    "    \"\"\"\n",
    "    def __init__(self, d_hid, d_inner_hid, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Conv1d(d_hid, d_inner_hid, 1)\n",
    "        self.w_2 = nn.Conv1d(d_inner_hid, d_hid, 1)\n",
    "        self.layer_norm = nn.LayerNorm(d_hid)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: torch.tensor,\n",
    "            size=(batch_size, max_length, d_hid)\n",
    "        :return: torch.tensor,\n",
    "            size=(batch_size, max_length, d_hid) \n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        output = self.relu(self.w_1(x.transpose(1, 2)))\n",
    "        output = self.w_2(output).transpose(2, 1)\n",
    "        output = self.dropout(output)\n",
    "        return self.layer_norm(output + residual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ④ Masking\n",
    "TransfomerではAttentionに対して2つのマスクを定義します。\n",
    "\n",
    "一つはkey側の系列のPADトークンに対してAttentionを行わないようにするマスクです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_attn_padding_mask(seq_q, seq_k):\n",
    "    \"\"\"\n",
    "    keyのPADに対するattentionを0にするためのマスクを作成する\n",
    "    :param seq_q: tensor, queryの系列, size=(batch_size, len_q)\n",
    "    :param seq_k: tensor, keyの系列, size=(batch_size, len_k)\n",
    "    :return pad_attn_mask: tensor, size=(batch_size, len_q, len_k)\n",
    "    \"\"\"\n",
    "    batch_size, len_q = seq_q.size()\n",
    "    batch_size, len_k = seq_k.size()\n",
    "    pad_attn_mask = seq_k.data.eq(PAD).unsqueeze(1)   # (N, 1, len_k)\n",
    "    pad_attn_mask = pad_attn_mask.expand(batch_size, len_q, len_k) # (N, len_q, len_k)\n",
    "    return pad_attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_seq_q = torch.tensor([[1, 2, 3]])\n",
    "_seq_k = torch.tensor([[4, 5, 6, 7, PAD]])\n",
    "_mask = get_attn_padding_mask(_seq_q, _seq_k)  # 行がquery、列がkeyに対応し、key側がPAD(=0)の時刻だけ1で他が0の行列ができる\n",
    "print('query:\\n', _seq_q)\n",
    "print('key:\\n', _seq_k)\n",
    "print('mask:\\n', _mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "もう一つはDecoder側でSelf Attentionを行う際に、各時刻で未来の情報に対するAttentionを行わないようにするマスクです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_attn_subsequent_mask(seq):\n",
    "    \"\"\"\n",
    "    未来の情報に対するattentionを0にするためのマスクを作成する\n",
    "    :param seq: tensor, size=(batch_size, length)\n",
    "    :return subsequent_mask: tensor, size=(batch_size, length, length)\n",
    "    \"\"\"\n",
    "    attn_shape = (seq.size(1), seq.size(1))\n",
    "    # 上三角行列(diagonal=1: 対角線より上が1で下が0)\n",
    "    subsequent_mask = torch.triu(torch.ones(attn_shape, dtype=torch.uint8, device=device), diagonal=1)\n",
    "    subsequent_mask = subsequent_mask.repeat(seq.size(0), 1, 1)\n",
    "    return subsequent_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iLectで実行する場合warning (GPU is too old) が出ますが, 実行に問題はないので気にせず進めてください.\n",
    "_seq = torch.tensor([[1,2,3,4]])\n",
    "_mask = get_attn_subsequent_mask(_seq)  # 行がquery、列がkeyに対応し、queryより未来のkeyの値が1で他は0の行列ができいる\n",
    "print('seq:\\n', _seq)\n",
    "print('mask:\\n', _mask)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. モデルの定義\n",
    "\n",
    "### Encoder\n",
    "これまで定義してきたサブレイヤーを統合して、Encoderを定義します。\n",
    "\n",
    "EncoderではSelf AttentionとPosition-Wise Feed Forward Networkからなるブロックを複数層繰り返すので、ブロックのクラスEncoderLayerを定義した後にEncoderを定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"\"\"Encoderのブロックのクラス\"\"\"\n",
    "    def __init__(self, d_model, d_inner_hid, n_head, d_k, d_v, dropout=0.1):\n",
    "        \"\"\"\n",
    "        :param d_model: int, 隠れ層の次元数\n",
    "        :param d_inner_hid: int, Position Wise Feed Forward Networkの隠れ層2層目の次元数\n",
    "        :param n_head: int,　ヘッド数\n",
    "        :param d_k: int, keyベクトルの次元数\n",
    "        :param d_v: int, valueベクトルの次元数\n",
    "        :param dropout: float, ドロップアウト率\n",
    "        \"\"\"\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        # Encoder内のSelf-Attention\n",
    "        self.slf_attn = MultiHeadAttention(\n",
    "            n_head, d_model, d_k, d_v, dropout=dropout)\n",
    "        # Postionwise FFN\n",
    "        self.pos_ffn = PositionwiseFeedForward(d_model, d_inner_hid, dropout=dropout)\n",
    "\n",
    "    def forward(self, enc_input, slf_attn_mask=None):\n",
    "        \"\"\"\n",
    "        :param enc_input: tensor, Encoderの入力, \n",
    "            size=(batch_size, max_length, d_model)\n",
    "        :param slf_attn_mask: tensor, Self Attentionの行列にかけるマスク, \n",
    "            size=(batch_size, len_q, len_k)\n",
    "        :return enc_output: tensor, Encoderの出力, \n",
    "            size=(batch_size, max_length, d_model)\n",
    "        :return enc_slf_attn: tensor, EncoderのSelf Attentionの行列, \n",
    "            size=(n_head*batch_size, len_q, len_k)\n",
    "        \"\"\"\n",
    "        # Self-Attentionのquery, key, valueにはすべてEncoderの入力（enc_input）が入る\n",
    "        enc_output, enc_slf_attn = self.slf_attn(\n",
    "            enc_input, enc_input, enc_input, attn_mask=slf_attn_mask)\n",
    "        enc_output = self.pos_ffn(enc_output)\n",
    "        return enc_output, enc_slf_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"EncoderLayerブロックからなるEncoderのクラス\"\"\"\n",
    "    def __init__(\n",
    "            self, n_src_vocab, max_length, n_layers=6, n_head=8, d_k=64, d_v=64,\n",
    "            d_word_vec=512, d_model=512, d_inner_hid=1024, dropout=0.1):\n",
    "        \"\"\"\n",
    "        :param n_src_vocab: int, 入力言語の語彙数\n",
    "        :param max_length: int, 最大系列長\n",
    "        :param n_layers: int, レイヤー数\n",
    "        :param n_head: int,　ヘッド数\n",
    "        :param d_k: int, keyベクトルの次元数\n",
    "        :param d_v: int, valueベクトルの次元数\n",
    "        :param d_word_vec: int, 単語の埋め込みの次元数\n",
    "        :param d_model: int, 隠れ層の次元数\n",
    "        :param d_inner_hid: int, Position Wise Feed Forward Networkの隠れ層2層目の次元数\n",
    "        :param dropout: float, ドロップアウト率        \n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        n_position = max_length + 1\n",
    "        self.max_length = max_length\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Positional Encodingを用いたEmbedding\n",
    "        self.position_enc = nn.Embedding(n_position, d_word_vec, padding_idx=PAD)\n",
    "        self.position_enc.weight.data = position_encoding_init(n_position, d_word_vec)\n",
    "\n",
    "        # 一般的なEmbedding\n",
    "        self.src_word_emb = nn.Embedding(n_src_vocab, d_word_vec, padding_idx=PAD)\n",
    "\n",
    "        # EncoderLayerをn_layers個積み重ねる\n",
    "        self.layer_stack = nn.ModuleList([\n",
    "            EncoderLayer(d_model, d_inner_hid, n_head, d_k, d_v, dropout=dropout)\n",
    "            for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, src_seq, src_pos):\n",
    "        \"\"\"\n",
    "        :param src_seq: tensor, 入力系列, \n",
    "            size=(batch_size, max_length)\n",
    "        :param src_pos: tensor, 入力系列の各単語の位置情報,\n",
    "            size=(batch_size, max_length)\n",
    "        :return enc_output: tensor, Encoderの最終出力, \n",
    "            size=(batch_size, max_length, d_model)\n",
    "        :return enc_slf_attns: list, EncoderのSelf Attentionの行列のリスト\n",
    "        \"\"\"\n",
    "        # 一般的な単語のEmbeddingを行う\n",
    "        enc_input = self.src_word_emb(src_seq)\n",
    "        # Positional EncodingのEmbeddingを加算する\n",
    "        enc_input += self.position_enc(src_pos)\n",
    "\n",
    "        enc_slf_attns = []\n",
    "        enc_output = enc_input\n",
    "        # key(=enc_input)のPADに対応する部分のみ1のマスクを作成\n",
    "        enc_slf_attn_mask = get_attn_padding_mask(src_seq, src_seq)\n",
    "\n",
    "        # n_layers個のEncoderLayerに入力を通す\n",
    "        for enc_layer in self.layer_stack:\n",
    "            enc_output, enc_slf_attn = enc_layer(\n",
    "                enc_output, slf_attn_mask=enc_slf_attn_mask)\n",
    "            enc_slf_attns += [enc_slf_attn]\n",
    "\n",
    "        return enc_output, enc_slf_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder\n",
    "\n",
    "Deocoderも同様にSelf Attention, Source-Target Attention, Position-Wise Feed Forward Networkからなるブロックを複数層繰り返ので、ブロックのクラスDecoderLayerを定義した後にDecoderを定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \"\"\"Decoderのブロックのクラス\"\"\"\n",
    "    def __init__(self, d_model, d_inner_hid, n_head, d_k, d_v, dropout=0.1):\n",
    "        \"\"\"\n",
    "        :param d_model: int, 隠れ層の次元数\n",
    "        :param d_inner_hid: int, Position Wise Feed Forward Networkの隠れ層2層目の次元数\n",
    "        :param n_head: int,　ヘッド数\n",
    "        :param d_k: int, keyベクトルの次元数\n",
    "        :param d_v: int, valueベクトルの次元数\n",
    "        :param dropout: float, ドロップアウト率\n",
    "        \"\"\"\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        # Decoder内のSelf-Attention\n",
    "        self.slf_attn = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout=dropout)\n",
    "        # Encoder-Decoder間のSource-Target Attention\n",
    "        self.enc_attn = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout=dropout)\n",
    "        # Positionwise FFN\n",
    "        self.pos_ffn = PositionwiseFeedForward(d_model, d_inner_hid, dropout=dropout)\n",
    "\n",
    "    def forward(self, dec_input, enc_output, slf_attn_mask=None, dec_enc_attn_mask=None):\n",
    "        \"\"\"\n",
    "        :param dec_input: tensor, Decoderの入力, \n",
    "            size=(batch_size, max_length, d_model)\n",
    "        :param enc_output: tensor, Encoderの出力, \n",
    "            size=(batch_size, max_length, d_model)\n",
    "        :param slf_attn_mask: tensor, Self Attentionの行列にかけるマスク, \n",
    "            size=(batch_size, len_q, len_k)\n",
    "        :param dec_enc_attn_mask: tensor, Soutce-Target Attentionの行列にかけるマスク, \n",
    "            size=(batch_size, len_q, len_k)\n",
    "        :return dec_output: tensor, Decoderの出力, \n",
    "            size=(batch_size, max_length, d_model)\n",
    "        :return dec_slf_attn: tensor, DecoderのSelf Attentionの行列, \n",
    "            size=(n_head*batch_size, len_q, len_k)\n",
    "        :return dec_enc_attn: tensor, DecoderのSoutce-Target Attentionの行列, \n",
    "            size=(n_head*batch_size, len_q, len_k)\n",
    "        \"\"\"\n",
    "        # Self-Attentionのquery, key, valueにはすべてDecoderの入力（dec_input）が入る\n",
    "        dec_output, dec_slf_attn = self.slf_attn(\n",
    "            dec_input, dec_input, dec_input, attn_mask=slf_attn_mask)\n",
    "        # Source-Target-AttentionのqueryにはDecoderの出力(dec_output), key, valueにはEncoderの出力（enc_output）が入る\n",
    "        dec_output, dec_enc_attn = self.enc_attn(\n",
    "            dec_output, enc_output, enc_output, attn_mask=dec_enc_attn_mask)\n",
    "        dec_output = self.pos_ffn(dec_output)\n",
    "\n",
    "        return dec_output, dec_slf_attn, dec_enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"DecoderLayerブロックからなるDecoderのクラス\"\"\"\n",
    "    def __init__(\n",
    "            self, n_tgt_vocab, max_length, n_layers=6, n_head=8, d_k=64, d_v=64,\n",
    "            d_word_vec=512, d_model=512, d_inner_hid=1024, dropout=0.1):\n",
    "        \"\"\"\n",
    "        :param n_tgt_vocab: int, 出力言語の語彙数\n",
    "        :param max_length: int, 最大系列長\n",
    "        :param n_layers: int, レイヤー数\n",
    "        :param n_head: int,　ヘッド数\n",
    "        :param d_k: int, keyベクトルの次元数\n",
    "        :param d_v: int, valueベクトルの次元数\n",
    "        :param d_word_vec: int, 単語の埋め込みの次元数\n",
    "        :param d_model: int, 隠れ層の次元数\n",
    "        :param d_inner_hid: int, Position Wise Feed Forward Networkの隠れ層2層目の次元数\n",
    "        :param dropout: float, ドロップアウト率        \n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        n_position = max_length + 1\n",
    "        self.max_length = max_length\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Positional Encodingを用いたEmbedding\n",
    "        self.position_enc = nn.Embedding(\n",
    "            n_position, d_word_vec, padding_idx=PAD)\n",
    "        self.position_enc.weight.data = position_encoding_init(n_position, d_word_vec)\n",
    "\n",
    "        # 一般的なEmbedding\n",
    "        self.tgt_word_emb = nn.Embedding(\n",
    "            n_tgt_vocab, d_word_vec, padding_idx=PAD)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # DecoderLayerをn_layers個積み重ねる\n",
    "        self.layer_stack = nn.ModuleList([\n",
    "            DecoderLayer(d_model, d_inner_hid, n_head, d_k, d_v, dropout=dropout)\n",
    "            for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, tgt_seq, tgt_pos, src_seq, enc_output):\n",
    "        \"\"\"\n",
    "        :param tgt_seq: tensor, 出力系列, \n",
    "            size=(batch_size, max_length)\n",
    "        :param tgt_pos: tensor, 出力系列の各単語の位置情報,\n",
    "            size=(batch_size, max_length)\n",
    "        :param src_seq: tensor, 入力系列, \n",
    "            size=(batch_size, n_src_vocab)\n",
    "        :param enc_output: tensor, Encoderの出力, \n",
    "            size=(batch_size, max_length, d_model)\n",
    "        :return dec_output: tensor, Decoderの最終出力, \n",
    "            size=(batch_size, max_length, d_model)\n",
    "        :return dec_slf_attns: list, DecoderのSelf Attentionの行列のリスト \n",
    "        :return dec_slf_attns: list, DecoderのSelf Attentionの行列のリスト\n",
    "        \"\"\"\n",
    "        # 一般的な単語のEmbeddingを行う\n",
    "        dec_input = self.tgt_word_emb(tgt_seq)\n",
    "        # Positional EncodingのEmbeddingを加算する\n",
    "        dec_input += self.position_enc(tgt_pos)\n",
    "\n",
    "        # Self-Attention用のマスクを作成\n",
    "        # key(=dec_input)のPADに対応する部分が1のマスクと、queryから見たkeyの未来の情報に対応する部分が1のマスクのORをとる\n",
    "        dec_slf_attn_pad_mask = get_attn_padding_mask(tgt_seq, tgt_seq)  # (N, max_length, max_length)\n",
    "        dec_slf_attn_sub_mask = get_attn_subsequent_mask(tgt_seq)  # (N, max_length, max_length)\n",
    "        dec_slf_attn_mask = torch.gt(dec_slf_attn_pad_mask + dec_slf_attn_sub_mask, 0)  # ORをとる\n",
    "\n",
    "        # key(=dec_input)のPADに対応する部分のみ1のマスクを作成\n",
    "        dec_enc_attn_pad_mask = get_attn_padding_mask(tgt_seq, src_seq)  # (N, max_length, max_length)\n",
    "\n",
    "        dec_slf_attns, dec_enc_attns = [], []\n",
    "\n",
    "        dec_output = dec_input\n",
    "        # n_layers個のDecoderLayerに入力を通す\n",
    "        for dec_layer in self.layer_stack:\n",
    "            dec_output, dec_slf_attn, dec_enc_attn = dec_layer(\n",
    "                dec_output, enc_output,\n",
    "                slf_attn_mask=dec_slf_attn_mask,\n",
    "                dec_enc_attn_mask=dec_enc_attn_pad_mask)\n",
    "\n",
    "            dec_slf_attns += [dec_slf_attn]\n",
    "            dec_enc_attns += [dec_enc_attn]\n",
    "\n",
    "        return dec_output, dec_slf_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer\n",
    "最後にモデル全体の機構を定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \"\"\"Transformerのモデル全体のクラス\"\"\"\n",
    "    def __init__(\n",
    "            self, n_src_vocab, n_tgt_vocab, max_length, n_layers=6, n_head=8,\n",
    "            d_word_vec=512, d_model=512, d_inner_hid=1024, d_k=64, d_v=64,\n",
    "            dropout=0.1, proj_share_weight=True):\n",
    "        \"\"\"\n",
    "        :param n_src_vocab: int, 入力言語の語彙数\n",
    "        :param n_tgt_vocab: int, 出力言語の語彙数\n",
    "        :param max_length: int, 最大系列長\n",
    "        :param n_layers: int, レイヤー数\n",
    "        :param n_head: int,　ヘッド数\n",
    "        :param d_k: int, keyベクトルの次元数\n",
    "        :param d_v: int, valueベクトルの次元数\n",
    "        :param d_word_vec: int, 単語の埋め込みの次元数\n",
    "        :param d_model: int, 隠れ層の次元数\n",
    "        :param d_inner_hid: int, Position Wise Feed Forward Networkの隠れ層2層目の次元数\n",
    "        :param dropout: float, ドロップアウト率        \n",
    "        :param proj_share_weight: bool, 出力言語の単語のEmbeddingと出力の写像で重みを共有する        \n",
    "        \"\"\"\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = Encoder(\n",
    "            n_src_vocab, max_length, n_layers=n_layers, n_head=n_head,\n",
    "            d_word_vec=d_word_vec, d_model=d_model,\n",
    "            d_inner_hid=d_inner_hid, dropout=dropout)\n",
    "        self.decoder = Decoder(\n",
    "            n_tgt_vocab, max_length, n_layers=n_layers, n_head=n_head,\n",
    "            d_word_vec=d_word_vec, d_model=d_model,\n",
    "            d_inner_hid=d_inner_hid, dropout=dropout)\n",
    "        self.tgt_word_proj = nn.Linear(d_model, n_tgt_vocab, bias=False)\n",
    "        nn.init.xavier_normal_(self.tgt_word_proj.weight)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        assert d_model == d_word_vec  # 各モジュールの出力のサイズは揃える\n",
    "\n",
    "        if proj_share_weight:\n",
    "            # 出力言語の単語のEmbeddingと出力の写像で重みを共有する\n",
    "            assert d_model == d_word_vec\n",
    "            self.tgt_word_proj.weight = self.decoder.tgt_word_emb.weight\n",
    "\n",
    "    def get_trainable_parameters(self):\n",
    "        # Positional Encoding以外のパラメータを更新する\n",
    "        enc_freezed_param_ids = set(map(id, self.encoder.position_enc.parameters()))\n",
    "        dec_freezed_param_ids = set(map(id, self.decoder.position_enc.parameters()))\n",
    "        freezed_param_ids = enc_freezed_param_ids | dec_freezed_param_ids\n",
    "        return (p for p in self.parameters() if id(p) not in freezed_param_ids)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_seq, src_pos = src\n",
    "        tgt_seq, tgt_pos = tgt\n",
    "\n",
    "        src_seq = src_seq[:, 1:]\n",
    "        src_pos = src_pos[:, 1:]\n",
    "        tgt_seq = tgt_seq[:, :-1]\n",
    "        tgt_pos = tgt_pos[:, :-1]\n",
    "\n",
    "        enc_output, *_ = self.encoder(src_seq, src_pos)\n",
    "        dec_output, *_ = self.decoder(tgt_seq, tgt_pos, src_seq, enc_output)\n",
    "        seq_logit = self.tgt_word_proj(dec_output)\n",
    "\n",
    "        return seq_logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_loss(batch_X, batch_Y, model, criterion, optimizer=None, is_train=True):\n",
    "    # バッチの損失を計算\n",
    "    model.train(is_train)\n",
    "    \n",
    "    pred_Y = model(batch_X, batch_Y)\n",
    "    gold = batch_Y[0][:, 1:].contiguous()\n",
    "    loss = criterion(pred_Y.view(-1, pred_Y.size(2)), gold.view(-1))\n",
    "\n",
    "    if is_train:  # 訓練時はパラメータを更新\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    gold = gold.data.cpu().numpy().tolist()\n",
    "    pred = pred_Y.max(dim=-1)[1].data.cpu().numpy().tolist()\n",
    "\n",
    "    return loss.item(), gold, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 20\n",
    "batch_size = 64\n",
    "num_epochs = 15\n",
    "lr = 0.001\n",
    "ckpt_path = 'transformer.pth'\n",
    "max_length = MAX_LENGTH + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_args = {\n",
    "    'n_src_vocab': vocab_size_X,\n",
    "    'n_tgt_vocab': vocab_size_Y,\n",
    "    'max_length': max_length,\n",
    "    'proj_share_weight': True,\n",
    "    'd_k': 32,\n",
    "    'd_v': 32,\n",
    "    'd_model': 128,\n",
    "    'd_word_vec': 128,\n",
    "    'd_inner_hid': 256,\n",
    "    'n_layers': 3,\n",
    "    'n_head': 6,\n",
    "    'dropout': 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DataLoaderやモデルを定義\n",
    "train_dataloader = DataLoader(\n",
    "    train_X, train_Y, batch_size\n",
    "    )\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_X, valid_Y, batch_size, \n",
    "    shuffle=False\n",
    "    )\n",
    "\n",
    "model = Transformer(**model_args).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.get_trainable_parameters(), lr=lr)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD, reduction='sum').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_bleu(refs, hyps):\n",
    "    \"\"\"\n",
    "    BLEUスコアを計算する関数\n",
    "    :param refs: list, 参照訳。単語のリストのリスト (例： [['I', 'have', 'a', 'pen'], ...])\n",
    "    :param hyps: list, モデルの生成した訳。単語のリストのリスト (例： [['I', 'have', 'a', 'pen'], ...])\n",
    "    :return: float, BLEUスコア(0~100)\n",
    "    \"\"\"\n",
    "    refs = [[ref[:ref.index(EOS)]] for ref in refs]\n",
    "    hyps = [hyp[:hyp.index(EOS)] if EOS in hyp else hyp for hyp in hyps]\n",
    "    return 100 * bleu_score.corpus_bleu(refs, hyps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練\n",
    "best_valid_bleu = 0.\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    start = time.time()\n",
    "    train_loss = 0.\n",
    "    train_refs = []\n",
    "    train_hyps = []\n",
    "    valid_loss = 0.\n",
    "    valid_refs = []\n",
    "    valid_hyps = []\n",
    "    # train\n",
    "    for batch in train_dataloader:\n",
    "        batch_X, batch_Y = batch\n",
    "        loss, gold, pred = compute_loss(\n",
    "            batch_X, batch_Y, model, criterion, optimizer, is_train=True\n",
    "            )\n",
    "        train_loss += loss\n",
    "        train_refs += gold\n",
    "        train_hyps += pred\n",
    "    # valid\n",
    "    for batch in valid_dataloader:\n",
    "        batch_X, batch_Y = batch\n",
    "        loss, gold, pred = compute_loss(\n",
    "            batch_X, batch_Y, model, criterion, is_train=False\n",
    "            )\n",
    "        valid_loss += loss\n",
    "        valid_refs += gold\n",
    "        valid_hyps += pred\n",
    "    # 損失をサンプル数で割って正規化\n",
    "    train_loss /= len(train_dataloader.data) \n",
    "    valid_loss /= len(valid_dataloader.data) \n",
    "    # BLEUを計算\n",
    "    train_bleu = calc_bleu(train_refs, train_hyps)\n",
    "    valid_bleu = calc_bleu(valid_refs, valid_hyps)\n",
    "\n",
    "    # validationデータでBLEUが改善した場合にはモデルを保存\n",
    "    if valid_bleu > best_valid_bleu:\n",
    "        ckpt = model.state_dict()\n",
    "        torch.save(ckpt, ckpt_path)\n",
    "        best_valid_bleu = valid_bleu\n",
    "\n",
    "    elapsed_time = (time.time()-start) / 60\n",
    "    print('Epoch {} [{:.1f}min]: train_loss: {:5.2f}  train_bleu: {:2.2f}  valid_loss: {:5.2f}  valid_bleu: {:2.2f}'.format(\n",
    "            epoch, elapsed_time, train_loss, train_bleu, valid_loss, valid_bleu))\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(model, src, max_length=20):\n",
    "    # 学習済みモデルで系列を生成する\n",
    "    model.eval()\n",
    "    \n",
    "    src_seq, src_pos = src\n",
    "    batch_size = src_seq.size(0)\n",
    "    enc_output, enc_slf_attns = model.encoder(src_seq, src_pos)\n",
    "        \n",
    "    tgt_seq = torch.full([batch_size, 1], BOS, dtype=torch.long, device=device)\n",
    "    tgt_pos = torch.arange(1, dtype=torch.long, device=device)\n",
    "    tgt_pos = tgt_pos.unsqueeze(0).repeat(batch_size, 1)\n",
    "\n",
    "    # 時刻ごとに処理\n",
    "    for t in range(1, max_length+1):\n",
    "        dec_output, dec_slf_attns, dec_enc_attns = model.decoder(\n",
    "            tgt_seq, tgt_pos, src_seq, enc_output)\n",
    "        dec_output = model.tgt_word_proj(dec_output)\n",
    "        out = dec_output[:, -1, :].max(dim=-1)[1].unsqueeze(1)\n",
    "        # 自身の出力を次の時刻の入力にする\n",
    "        tgt_seq = torch.cat([tgt_seq, out], dim=-1)\n",
    "        tgt_pos = torch.arange(t+1, dtype=torch.long, device=device)\n",
    "        tgt_pos = tgt_pos.unsqueeze(0).repeat(batch_size, 1)\n",
    "\n",
    "    return tgt_seq[:, 1:], enc_slf_attns, dec_slf_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ids_to_sentence(vocab, ids):\n",
    "    # IDのリストを単語のリストに変換する\n",
    "    return [vocab.id2word[_id] for _id in ids]\n",
    "\n",
    "def trim_eos(ids):\n",
    "    # IDのリストからEOS以降の単語を除外する\n",
    "    if EOS in ids:\n",
    "        return ids[:ids.index(EOS)]\n",
    "    else:\n",
    "        return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 学習済みモデルの読み込み\n",
    "model = Transformer(**model_args).to(device)\n",
    "ckpt = torch.load(ckpt_path)\n",
    "model.load_state_dict(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# テストデータの読み込み\n",
    "test_X = load_data('../data/dev.en')\n",
    "test_Y = load_data('../data/dev.ja')\n",
    "test_X = [sentence_to_ids(vocab_X, sentence) for sentence in test_X]\n",
    "test_Y = [sentence_to_ids(vocab_Y, sentence) for sentence in test_Y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "    test_X, test_Y, 1,\n",
    "    shuffle=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "src, tgt = next(test_dataloader)\n",
    "\n",
    "src_ids = src[0][0].cpu().numpy()\n",
    "tgt_ids = tgt[0][0].cpu().numpy()\n",
    "\n",
    "print('src: {}'.format(' '.join(ids_to_sentence(vocab_X, src_ids[1:-1]))))\n",
    "print('tgt: {}'.format(' '.join(ids_to_sentence(vocab_Y, tgt_ids[1:-1]))))\n",
    "\n",
    "preds, enc_slf_attns, dec_slf_attns, dec_enc_attns = test(model, src)\n",
    "pred_ids = preds[0].data.cpu().numpy().tolist()\n",
    "print('out: {}'.format(' '.join(ids_to_sentence(vocab_Y, trim_eos(pred_ids)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLEUの評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# BLEUの評価\n",
    "test_dataloader = DataLoader(\n",
    "    test_X, test_Y, 128,\n",
    "    shuffle=False\n",
    "    )\n",
    "refs_list = []\n",
    "hyp_list = []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    batch_X, batch_Y = batch\n",
    "    preds, *_ = test(model, batch_X)\n",
    "    preds = preds.data.cpu().numpy().tolist()\n",
    "    refs = batch_Y[0].data.cpu().numpy()[:, 1:].tolist()\n",
    "    refs_list += refs\n",
    "    hyp_list += preds\n",
    "bleu = calc_bleu(refs_list, hyp_list)\n",
    "print(bleu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Attentionの可視化\n",
    "\n",
    "学習済みモデルのAttentionを可視化します。\n",
    "\n",
    "以下は元論文の図で、Encoder側のあるレイヤーにおけるSelf-Attentionを可視化したものです。\n",
    "\n",
    "異なる色が異なるヘッドを、色の濃淡がAttentionの重みを表しており、各ヘッドが異なる位置へのAttentionを担っていることがわかります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/AttentionVisualization.png\" style=\"height:400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下ではもう少し単純に、各行をquery、各列をkeyとしてAttentionの行列を可視化します。\n",
    "\n",
    "モデルはEncoder/Decoderそれぞれが複数のレイヤーを有し、各レイヤー内の各Attentionも複数のヘッドを有するので、順番に中身を可視化していきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_attentions(attention, sent_q, sent_k, n_max=10):\n",
    "    # Attentionの行列を可視化する(n_maxは表示するヘッドの最大数)\n",
    "    # EOS以降を削除\n",
    "    q_eos = sent_q.index(EOS_TOKEN)\n",
    "    k_eos = sent_k.index(EOS_TOKEN)\n",
    "    sent_q = sent_q[:q_eos+1]\n",
    "    sent_k = sent_k[:k_eos+1]\n",
    "    \n",
    "    n_head = attention.size(0)\n",
    "    n_head = min(n_head, n_max)\n",
    "    fig, axes = plt.subplots(1, n_head, figsize=(20, 8))\n",
    "    for h in range(n_head):\n",
    "        data = attention[h].cpu().data[:q_eos+1, :k_eos+1]\n",
    "        x = sent_k\n",
    "        y = sent_q if h == 0 else []\n",
    "        sns.heatmap(data, vmin=0., vmax=1., cbar=False, ax=axes[h], cmap='Blues')\n",
    "        axes[h].set_xticklabels(x)\n",
    "        axes[h].set_yticklabels(y, rotation=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_context('poster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src_sent = [vocab_X.id2word[i] for i in src_ids[1:]]\n",
    "pred_sent = [vocab_Y.id2word[i] for i in pred_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 1st layer\n",
    "show_attentions(enc_slf_attns[0], src_sent, src_sent, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 2nd layer\n",
    "show_attentions(enc_slf_attns[1], src_sent, src_sent, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 3rd layer\n",
    "show_attentions(enc_slf_attns[2], src_sent, src_sent, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 1st layer\n",
    "show_attentions(dec_slf_attns[0], pred_sent, pred_sent, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 2nd layer\n",
    "show_attentions(dec_slf_attns[1], pred_sent, pred_sent, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 3rd layer\n",
    "show_attentions(dec_slf_attns[2], pred_sent, pred_sent, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder Decoder Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 1st layer\n",
    "show_attentions(dec_enc_attns[0], pred_sent, src_sent, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 2nd layer\n",
    "show_attentions(dec_enc_attns[1], pred_sent, src_sent, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 3rd layer\n",
    "show_attentions(dec_enc_attns[2], pred_sent, src_sent, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
